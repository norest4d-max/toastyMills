# Copy to .env (kept local; NOT committed)
#
# Local Ollama default:
# - Ollama server: http://localhost:11434
# - Keeps all prompts/results on your machine unless you change it.
REACT_APP_OLLAMA_BASE_URL=http://localhost:11434

# Off by default: keeps ToastyMills strictly dictionary-driven unless you opt in.
REACT_APP_OLLAMA_ENABLED=0

# Default model name to request from your Ollama server.
REACT_APP_OLLAMA_MODEL=llama3.2

# When enabled, unknown `define <word>` requests can be generated via Ollama and saved locally.
# Off by default to avoid silently adding inaccurate data.
REACT_APP_AUTO_LEARN=0

# When Ollama is enabled, let it respond with light humor if the user is joking.
REACT_APP_HUMOR_MODE=1

# Optional: connect React Chat to the local Python rig bridge.
REACT_APP_RIG_BRIDGE_ENABLED=0
REACT_APP_RIG_BRIDGE_URL=http://127.0.0.1:8787

# Optional: automatically open a browser definition lookup when you `define <word>` and it's unknown.
# This will open a new tab/window, so keep it OFF unless you want that behavior.
REACT_APP_AUTO_LOOKUP_DEFINE=0
